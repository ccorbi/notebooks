{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sklearn\n",
    "from sklearn import neighbors\n",
    "\n",
    "from pandas_summary import DataFrameSummary\n",
    "from pandas.api.types import is_string_dtype, is_numeric_dtype\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Imputer:\n",
    "    \"\"\"Imputer class.\"\"\"\n",
    "    def __init():\n",
    "        return\n",
    "\n",
    "    def _fit(self, X, column, k=10, is_categorical=False):\n",
    "        \"\"\"Fit a knn classifier for missing column.\n",
    "        - Args:\n",
    "                X(numpy.ndarray): input data\n",
    "                column(int): column id to be imputed\n",
    "                k(int): number of nearest neighbors, default 10\n",
    "                is_categorical(boolean): is continuous or categorical feature\n",
    "        - Returns:\n",
    "                clf: trained k nearest neighbour classifier\n",
    "        \"\"\"\n",
    "        clf = None\n",
    "        if not is_categorical:\n",
    "            clf = neighbors.KNeighborsRegressor(n_neighbors=k)\n",
    "        else:\n",
    "            clf = neighbors.KNeighborsClassifier(n_neighbors=k)\n",
    "        # use column not null to train the kNN classifier\n",
    "        missing_idxes = np.where(pd.isnull(X[:, column]))[0]\n",
    "        if len(missing_idxes) == 0:\n",
    "            return None\n",
    "        X_copy = np.delete(X, missing_idxes, 0)\n",
    "        X_train = np.delete(X_copy, column, 1)\n",
    "        # if other columns still have missing values fill with mean\n",
    "        col_mean = None\n",
    "        if not is_categorical:\n",
    "            col_mean = np.nanmean(X, 0)\n",
    "        else:\n",
    "            col_mean = np.nanmedian(X, 0)\n",
    "        for col_id in range(0, len(col_mean) - 1):\n",
    "            col_missing_idxes = np.where(np.isnan(X_train[:, col_id]))[0]\n",
    "            if len(col_missing_idxes) == 0:\n",
    "                continue\n",
    "            else:\n",
    "                X_train[col_missing_idxes, col_id] = col_mean[col_id]\n",
    "        y_train = X_copy[:, column]\n",
    "        # fit classifier\n",
    "        clf.fit(X_train, y_train)\n",
    "        return clf\n",
    "\n",
    "    def _transform(self, X, column, clf, is_categorical):\n",
    "        \"\"\"Impute missing values.\n",
    "        - Args:\n",
    "                X(numpy.ndarray): input numpy ndarray\n",
    "                column(int): index of column to be imputed\n",
    "                clf: pretrained classifier\n",
    "                is_categorical(boolean): is continuous or categorical feature\n",
    "        - Returns:\n",
    "                X(pandas.dataframe): imputed dataframe\n",
    "        \"\"\"\n",
    "        missing_idxes = np.where(np.isnan(X[:, column]))[0]\n",
    "        X_test = X[missing_idxes, :]\n",
    "        X_test = np.delete(X_test, column, 1)\n",
    "        # if other columns still have missing values fill with mean\n",
    "        col_mean = None\n",
    "        if not is_categorical:\n",
    "            col_mean = np.nanmean(X, 0)\n",
    "        else:\n",
    "            col_mean = np.nanmedian(X, 0)\n",
    "        # fill missing values in each column with current col_mean\n",
    "        for col_id in range(0, len(col_mean) - 1):\n",
    "            col_missing_idxes = np.where(np.isnan(X_test[:, col_id]))[0]\n",
    "            # if no missing values for current column\n",
    "            if len(col_missing_idxes) == 0:\n",
    "                continue\n",
    "            else:\n",
    "                X_test[col_missing_idxes, col_id] = col_mean[col_id]\n",
    "        # predict missing values\n",
    "        y_test = clf.predict(X_test)\n",
    "        print(y_test)\n",
    "        X[missing_idxes, column] = y_test\n",
    "        return X\n",
    "\n",
    "\n",
    "\n",
    "    def _check_X_y(self, X, column):\n",
    "        \"\"\"Check input, if pandas.dataframe, transform to numpy array.\n",
    "        - Args:\n",
    "                X(ndarray/pandas.dataframe): input instances\n",
    "                column(str/int): column index or column name\n",
    "        - Returns:\n",
    "                X(ndarray): input instances\n",
    "        \"\"\"\n",
    "        column_idx = None\n",
    "        X = X.select_dtypes(include=[np.number])\n",
    "\n",
    "        if isinstance(X, pd.core.frame.DataFrame):\n",
    "            if isinstance(column, str):\n",
    "                # get index of current column\n",
    "                column_idx = X.columns.get_loc(column)\n",
    "            else:\n",
    "                column_idx = column\n",
    "            X = X.as_matrix()\n",
    "        else:\n",
    "            column_idx = column\n",
    "        return X, column_idx\n",
    "    \n",
    "    \n",
    "    def knn(self, X, column, k=10, is_categorical=False):\n",
    "        \"\"\"Impute missing value with knn.\n",
    "        - Args:\n",
    "                X(pandas.dataframe): dataframe\n",
    "                column(str): column name to be imputed\n",
    "                k(int): number of nearest neighbors, default 10\n",
    "                is_categorical(boolean): is continuous or categorical feature\n",
    "        - Returns:\n",
    "                X_imputed(pandas.dataframe): imputed pandas dataframe\n",
    "        \"\"\"\n",
    "        X, column_id = self._check_X_y(X, column)\n",
    "        clf = self._fit(X, column_id, k, is_categorical)\n",
    "        if clf is None:\n",
    "            return X[;,column_id]\n",
    "        else:\n",
    "            X_imputed = self._transform(X, column_id, clf, is_categorical)\n",
    "            return X_imputed[:,column_id]\n",
    "        \n",
    "        \n",
    "\n",
    "def combine_date(years, months=1, days=1, weeks=None, hours=None, minutes=None,\n",
    "              seconds=None, milliseconds=None, microseconds=None, nanoseconds=None):\n",
    "    years = np.asarray(years) - 1970\n",
    "    months = np.asarray(months) - 1\n",
    "    days = np.asarray(days) - 1\n",
    "    types = ('<M8[Y]', '<m8[M]', '<m8[D]', '<m8[W]', '<m8[h]',\n",
    "             '<m8[m]', '<m8[s]', '<m8[ms]', '<m8[us]', '<m8[ns]')\n",
    "    vals = (years, months, days, weeks, hours, minutes, seconds,\n",
    "            milliseconds, microseconds, nanoseconds)\n",
    "    return sum(np.asarray(v, dtype=t) for t, v in zip(types, vals)\n",
    "               if v is not None)\n",
    "\n",
    "def expand_date(df, fldname, drop=True):\n",
    "    \"\"\"add_datepart converts a column of df from a datetime64 to many columns containing\n",
    "    the information from the date. This applies changes inplace.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df: A pandas data frame. df gain several new columns.\n",
    "    fldname: A string that is the name of the date column you wish to expand.\n",
    "        If it is not a datetime64 series, it will be converted to one with pd.to_datetime.\n",
    "    drop: If true then the original date column will be removed.\n",
    "\n",
    "    Examples:\n",
    "    ---------\n",
    "\n",
    "    >>> df = pd.DataFrame({ 'A' : pd.to_datetime(['3/11/2000', '3/12/2000', '3/13/2000'], infer_datetime_format=False) })\n",
    "    >>> df\n",
    "\n",
    "        A\n",
    "    0   2000-03-11\n",
    "    1   2000-03-12\n",
    "    2   2000-03-13\n",
    "\n",
    "    >>> add_datepart(df, 'A')\n",
    "    >>> df\n",
    "\n",
    "        AYear AMonth AWeek ADay ADayofweek ADayofyear AIs_month_end AIs_month_start AIs_quarter_end AIs_quarter_start AIs_year_end AIs_year_start AElapsed\n",
    "    0   2000  3      10    11   5          71         False         False           False           False             False        False          952732800\n",
    "    1   2000  3      10    12   6          72         False         False           False           False             False        False          952819200\n",
    "    2   2000  3      11    13   0          73         False         False           False           False             False        False          952905600\n",
    "    \"\"\"\n",
    "    fld = df[fldname]\n",
    "    if not np.issubdtype(fld.dtype, np.datetime64):\n",
    "        df[fldname] = fld = pd.to_datetime(fld, infer_datetime_format=True)\n",
    "    targ_pre = re.sub('[Dd]ate$', '', fldname)\n",
    "    for n in ('Year', 'Month', 'Week', 'Day', 'Dayofweek', 'Dayofyear',\n",
    "            'Is_month_end', 'Is_month_start', 'Is_quarter_end', 'Is_quarter_start', 'Is_year_end', 'Is_year_start'):\n",
    "        df[targ_pre+n] = getattr(fld.dt,n.lower())\n",
    "    df[targ_pre+'Elapsed'] = fld.astype(np.int64) // 10**9\n",
    "    if drop: df.drop(fldname, axis=1, inplace=True)\n",
    "\n",
    "def is_date(x): return np.issubdtype(x.dtype, np.datetime64)\n",
    "\n",
    "def to_cats(df):\n",
    "    \"\"\"Change any columns of strings in a panda's dataframe to a column of\n",
    "    catagorical values. This applies the changes inplace.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df: A pandas dataframe. Any columns of strings will be changed to\n",
    "        categorical values.\n",
    "\n",
    "    Examples:\n",
    "    ---------\n",
    "\n",
    "    >>> df = pd.DataFrame({'col1' : [1, 2, 3], 'col2' : ['a', 'b', 'a']})\n",
    "    >>> df\n",
    "       col1 col2\n",
    "    0     1    a\n",
    "    1     2    b\n",
    "    2     3    a\n",
    "\n",
    "    note the type of col2 is string\n",
    "\n",
    "    >>> train_cats(df)\n",
    "    >>> df\n",
    "\n",
    "       col1 col2\n",
    "    0     1    a\n",
    "    1     2    b\n",
    "    2     3    a\n",
    "\n",
    "    now the type of col2 is category\n",
    "    \"\"\"\n",
    "    for n,c in df.items():\n",
    "        if is_string_dtype(c): df[n] = c.astype('category').cat.as_ordered()\n",
    "\n",
    "def apply_cats(df, trn):\n",
    "    \"\"\"Changes any columns of strings in df into categorical variables using trn as\n",
    "    a template for the category codes.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df: A pandas dataframe. Any columns of strings will be changed to\n",
    "        categorical values. The category codes are determined by trn.\n",
    "\n",
    "    trn: A pandas dataframe. When creating a category for df, it looks up the\n",
    "        what the category's code were in trn and makes those the category codes\n",
    "        for df.\n",
    "\n",
    "    Examples:\n",
    "    ---------\n",
    "    >>> df = pd.DataFrame({'col1' : [1, 2, 3], 'col2' : ['a', 'b', 'a']})\n",
    "    >>> df\n",
    "       col1 col2\n",
    "    0     1    a\n",
    "    1     2    b\n",
    "    2     3    a\n",
    "\n",
    "    note the type of col2 is string\n",
    "\n",
    "    >>> train_cats(df)\n",
    "    >>> df\n",
    "\n",
    "       col1 col2\n",
    "    0     1    a\n",
    "    1     2    b\n",
    "    2     3    a\n",
    "\n",
    "    now the type of col2 is category {a : 1, b : 2}\n",
    "\n",
    "    >>> df2 = pd.DataFrame({'col1' : [1, 2, 3], 'col2' : ['b', 'a', 'a']})\n",
    "    >>> apply_cats(df2, df)\n",
    "\n",
    "           col1 col2\n",
    "        0     1    b\n",
    "        1     2    a\n",
    "        2     3    a\n",
    "\n",
    "    now the type of col is category {a : 1, b : 2}\n",
    "    \"\"\"\n",
    "    for n,c in df.items():\n",
    "        if (n in trn.columns) and (trn[n].dtype.name=='category'):\n",
    "            df[n] = pd.Categorical(c, categories=trn[n].cat.categories, ordered=True)\n",
    "\n",
    "def fix_missing(df, col, name, na_dict):\n",
    "    \"\"\" Fill missing data in a column of df with the median, and add a {name}_na column\n",
    "    which specifies if the data was missing.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df: The data frame that will be changed.\n",
    "\n",
    "    col: The column of data to fix by filling in missing data.\n",
    "\n",
    "    name: The name of the new filled column in df.\n",
    "\n",
    "    na_dict: A dictionary of values to create na's of and the value to insert. If\n",
    "        name is not a key of na_dict the median will fill any missing data. Also\n",
    "        if name is not a key of na_dict and there is no missing data in col, then\n",
    "        no {name}_na column is not created.\n",
    "\n",
    "\n",
    "    Examples:\n",
    "    ---------\n",
    "    >>> df = pd.DataFrame({'col1' : [1, np.NaN, 3], 'col2' : [5, 2, 2]})\n",
    "    >>> df\n",
    "       col1 col2\n",
    "    0     1    5\n",
    "    1   nan    2\n",
    "    2     3    2\n",
    "\n",
    "    >>> fix_missing(df, df['col1'], 'col1', {})\n",
    "    >>> df\n",
    "       col1 col2 col1_na\n",
    "    0     1    5   False\n",
    "    1     2    2    True\n",
    "    2     3    2   False\n",
    "\n",
    "\n",
    "    >>> df = pd.DataFrame({'col1' : [1, np.NaN, 3], 'col2' : [5, 2, 2]})\n",
    "    >>> df\n",
    "       col1 col2\n",
    "    0     1    5\n",
    "    1   nan    2\n",
    "    2     3    2\n",
    "\n",
    "    >>> fix_missing(df, df['col2'], 'col2', {})\n",
    "    >>> df\n",
    "       col1 col2\n",
    "    0     1    5\n",
    "    1   nan    2\n",
    "    2     3    2\n",
    "\n",
    "\n",
    "    >>> df = pd.DataFrame({'col1' : [1, np.NaN, 3], 'col2' : [5, 2, 2]})\n",
    "    >>> df\n",
    "       col1 col2\n",
    "    0     1    5\n",
    "    1   nan    2\n",
    "    2     3    2\n",
    "\n",
    "    >>> fix_missing(df, df['col1'], 'col1', {'col1' : 500})\n",
    "    >>> df\n",
    "       col1 col2 col1_na\n",
    "    0     1    5   False\n",
    "    1   500    2    True\n",
    "    2     3    2   False\n",
    "    \"\"\"\n",
    "    if is_numeric_dtype(col):\n",
    "        if pd.isnull(col).sum() or (name in na_dict):\n",
    "            df[name+'_na'] = pd.isnull(col)\n",
    "            filler = na_dict[name] if name in na_dict else col.median()\n",
    "            df[name] = col.fillna(filler)\n",
    "            na_dict[name] = filler\n",
    "    return na_dict\n",
    "\n",
    "def numericalize(df, col, name, max_n_cat):\n",
    "    \"\"\" Changes the column col from a categorical type to it's integer codes.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df: A pandas dataframe. df[name] will be filled with the integer codes from\n",
    "        col.\n",
    "\n",
    "    col: The column you wish to change into the categories.\n",
    "    name: The column name you wish to insert into df. This column will hold the\n",
    "        integer codes.\n",
    "\n",
    "    max_n_cat: If col has more categories than max_n_cat it will not change the\n",
    "        it to its integer codes. If max_n_cat is None, then col will always be\n",
    "        converted.\n",
    "\n",
    "    Examples:\n",
    "    ---------\n",
    "    >>> df = pd.DataFrame({'col1' : [1, 2, 3], 'col2' : ['a', 'b', 'a']})\n",
    "    >>> df\n",
    "       col1 col2\n",
    "    0     1    a\n",
    "    1     2    b\n",
    "    2     3    a\n",
    "\n",
    "    note the type of col2 is string\n",
    "\n",
    "    >>> train_cats(df)\n",
    "    >>> df\n",
    "\n",
    "       col1 col2\n",
    "    0     1    a\n",
    "    1     2    b\n",
    "    2     3    a\n",
    "\n",
    "    now the type of col2 is category { a : 1, b : 2}\n",
    "\n",
    "    >>> numericalize(df, df['col2'], 'col3', None)\n",
    "\n",
    "       col1 col2 col3\n",
    "    0     1    a    1\n",
    "    1     2    b    2\n",
    "    2     3    a    1\n",
    "    \"\"\"\n",
    "    if not is_numeric_dtype(col) and ( max_n_cat is None or col.nunique()>max_n_cat):\n",
    "        df[name] = col.cat.codes+1\n",
    "\n",
    "def scale_vars(df, mapper):\n",
    "    warnings.filterwarnings('ignore', category=sklearn.exceptions.DataConversionWarning)\n",
    "    if mapper is None:\n",
    "        map_f = [([n],StandardScaler()) for n in df.columns if is_numeric_dtype(df[n])]\n",
    "        mapper = DataFrameMapper(map_f).fit(df)\n",
    "    df[mapper.transformed_names_] = mapper.transform(df)\n",
    "    return mapper\n",
    "\n",
    "def proc_df(df, y_fld=None, skip_flds=None, do_scale=False, na_dict=None,\n",
    "            preproc_fn=None, max_n_cat=None, subset=None, mapper=None):\n",
    "\n",
    "    \"\"\" proc_df takes a data frame df and splits off the response variable, and\n",
    "    changes the df into an entirely numeric dataframe.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df: The data frame you wish to process.\n",
    "\n",
    "    y_fld: The name of the response variable\n",
    "\n",
    "    skip_flds: A list of fields that dropped from df.\n",
    "\n",
    "    do_scale: Standardizes each column in df,Takes Boolean Values(True,False)\n",
    "\n",
    "    na_dict: a dictionary of na columns to add. Na columns are also added if there\n",
    "        are any missing values.\n",
    "\n",
    "    preproc_fn: A function that gets applied to df.\n",
    "\n",
    "    max_n_cat: The maximum number of categories to break into dummy values, instead\n",
    "        of integer codes.\n",
    "\n",
    "    subset: Takes a random subset of size subset from df.\n",
    "\n",
    "    mapper: If do_scale is set as True, the mapper variable\n",
    "        calculates the values used for scaling of variables during training time(mean and standard deviation).\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    [x, y, nas, mapper(optional)]:\n",
    "\n",
    "        x: x is the transformed version of df. x will not have the response variable\n",
    "            and is entirely numeric.\n",
    "\n",
    "        y: y is the response variable\n",
    "\n",
    "        nas: returns a dictionary of which nas it created, and the associated median.\n",
    "\n",
    "        mapper: A DataFrameMapper which stores the mean and standard deviation of the corresponding continous\n",
    "        variables which is then used for scaling of during test-time.\n",
    "\n",
    "    Examples:\n",
    "    ---------\n",
    "    >>> df = pd.DataFrame({'col1' : [1, 2, 3], 'col2' : ['a', 'b', 'a']})\n",
    "    >>> df\n",
    "       col1 col2\n",
    "    0     1    a\n",
    "    1     2    b\n",
    "    2     3    a\n",
    "\n",
    "    note the type of col2 is string\n",
    "\n",
    "    >>> train_cats(df)\n",
    "    >>> df\n",
    "\n",
    "       col1 col2\n",
    "    0     1    a\n",
    "    1     2    b\n",
    "    2     3    a\n",
    "\n",
    "    now the type of col2 is category { a : 1, b : 2}\n",
    "\n",
    "    >>> x, y, nas = proc_df(df, 'col1')\n",
    "    >>> x\n",
    "\n",
    "       col2\n",
    "    0     1\n",
    "    1     2\n",
    "    2     1\n",
    "\n",
    "    >>> data = DataFrame(pet=[\"cat\", \"dog\", \"dog\", \"fish\", \"cat\", \"dog\", \"cat\", \"fish\"],\n",
    "                 children=[4., 6, 3, 3, 2, 3, 5, 4],\n",
    "                 salary=[90, 24, 44, 27, 32, 59, 36, 27])\n",
    "\n",
    "    >>> mapper = DataFrameMapper([(:pet, LabelBinarizer()),\n",
    "                          ([:children], StandardScaler())])\n",
    "\n",
    "    >>>round(fit_transform!(mapper, copy(data)), 2)\n",
    "\n",
    "    8x4 Array{Float64,2}:\n",
    "    1.0  0.0  0.0   0.21\n",
    "    0.0  1.0  0.0   1.88\n",
    "    0.0  1.0  0.0  -0.63\n",
    "    0.0  0.0  1.0  -0.63\n",
    "    1.0  0.0  0.0  -1.46\n",
    "    0.0  1.0  0.0  -0.63\n",
    "    1.0  0.0  0.0   1.04\n",
    "    0.0  0.0  1.0   0.21\n",
    "    \"\"\"\n",
    "    if not skip_flds: skip_flds=[]\n",
    "    if subset: df = get_sample(df,subset)\n",
    "    df = df.copy()\n",
    "    if preproc_fn: preproc_fn(df)\n",
    "    if y_fld is None: y = None\n",
    "    else:\n",
    "        if not is_numeric_dtype(df[y_fld]): df[y_fld] = df[y_fld].cat.codes\n",
    "        y = df[y_fld].values\n",
    "        skip_flds += [y_fld]\n",
    "    df.drop(skip_flds, axis=1, inplace=True)\n",
    "\n",
    "    if na_dict is None: na_dict = {}\n",
    "    for n,c in df.items(): na_dict = fix_missing(df, c, n, na_dict)\n",
    "    if do_scale: mapper = scale_vars(df, mapper)\n",
    "    for n,c in df.items(): numericalize(df, c, n, max_n_cat)\n",
    "    res = [pd.get_dummies(df, dummy_na=True), y, na_dict]\n",
    "    if do_scale: res = res + [mapper]\n",
    "    return res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_PANDASUTILS_LOADED = True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
